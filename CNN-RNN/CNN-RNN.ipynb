{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931a3ea1",
   "metadata": {},
   "source": [
    "# CNN-RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542cd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts'))\n",
    "sys.path.append(scripts_dir)\n",
    "from data_generator import normalize_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f51834",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43213dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and base filename pattern\n",
    "file_pattern = \"../data/final_data/cleaned_compiled_data_normalized_part*.csv\"\n",
    "\n",
    "# Use glob to get a sorted list of all matching CSV parts\n",
    "csv_files = sorted(glob.glob(file_pattern))\n",
    "\n",
    "# Load and concatenate all parts\n",
    "data = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# Done! Now `data` holds the full combined normalized DataFrame\n",
    "print(f\"Loaded {len(csv_files)} files. Final shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c4273",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_stations = ['S104', 'S107', 'S109', 'S115', 'S116', 'S24', 'S43', 'S50']\n",
    "pixel_coords = [(4, 11, 'S109'),\n",
    " (2, 7, 'S50'),\n",
    " (1, 16, 'S107'),\n",
    " (2, 13, 'S43'),\n",
    " (0, 0, 'S115'),\n",
    " (4, 17, 'S24'),\n",
    " (0, 6, 'S116'),\n",
    " (8, 8, 'S104')]\n",
    "def tabular_to_image(data: pd.DataFrame, pixel_coords, image_shape=(9, 18)):\n",
    "    feature_types = ['rainfall', 'air_temperature', 'wind_speed', 'relative_humidity', 'wind_direction']\n",
    "    H, W = image_shape\n",
    "    T = data.shape[0]\n",
    "    image = np.full((T, H, W, len(feature_types)), np.nan, dtype=np.float32)\n",
    "\n",
    "    feature_to_channel = {feat: i for i, feat in enumerate(feature_types)}\n",
    "\n",
    "    for y, x, station_id in pixel_coords:\n",
    "        for feat in feature_types:\n",
    "            col_name = f\"{feat}_{station_id}\"\n",
    "            if col_name in data.columns:\n",
    "                channel = feature_to_channel[feat]\n",
    "                image[:, y, x, channel] = data[col_name].values\n",
    "\n",
    "    return image if T > 1 else image[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningDataset_Modified(Dataset):\n",
    "    def __init__(self, compiled_df, pixel_coords, image_shape=(9, 18), timezone_str=\"Asia/Singapore\", reject_zeros = True):\n",
    "        self.compiled_df = compiled_df.copy()\n",
    "        self.pixel_coords = pixel_coords\n",
    "        self.image_shape = image_shape\n",
    "        self.timezone = pytz.timezone(timezone_str)\n",
    "        self.samples = []\n",
    "        self.reject_zeros = reject_zeros\n",
    "\n",
    "        self._prepare_dataset()\n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        # Ensure datetime index\n",
    "        self.compiled_df[\"Timestamp\"] = pd.to_datetime(self.compiled_df[\"Timestamp\"])\n",
    "        if not isinstance(self.compiled_df.index, pd.DatetimeIndex):\n",
    "            self.compiled_df.set_index(\"Timestamp\", inplace=True)\n",
    "        self.compiled_df.index = self.compiled_df.index.tz_localize(None)\n",
    "\n",
    "        # Drop target for input features\n",
    "        input_df = self.compiled_df.drop(columns=[\"Lightning_Risk\"])\n",
    "\n",
    "        # Valid 2-hour timestamps\n",
    "        min_ts = self.compiled_df.index.min().ceil(\"2h\") + pd.Timedelta(hours=2)\n",
    "        max_ts = self.compiled_df.index.max().floor(\"2h\")\n",
    "        valid_ts = self.compiled_df.loc[\n",
    "            (self.compiled_df.index >= min_ts) &\n",
    "            (self.compiled_df.index <= max_ts) &\n",
    "            (self.compiled_df.index.hour % 2 == 0) &\n",
    "            (self.compiled_df.index.minute == 0)\n",
    "        ].index\n",
    "\n",
    "        for timestamp in valid_ts:\n",
    "            try:\n",
    "                # Input time windows (past 5)\n",
    "                input_times = [timestamp - pd.Timedelta(minutes=delta) for delta in [120, 90, 60, 30, 0]]\n",
    "                input_slices = self.compiled_df.loc[input_times]\n",
    "                input_images = tabular_to_image(input_slices, self.pixel_coords, self.image_shape)  # (5, H, W, C)\n",
    "\n",
    "                # Rearrange to (C, T, H, W) if needed\n",
    "                input_tensor = np.transpose(input_images, (3, 0, 1, 2))  # (C, T, H, W)\n",
    "\n",
    "                # Output time windows (future 5)\n",
    "                output_times = [timestamp + pd.Timedelta(minutes=delta) for delta in [0, 30, 60, 90, 120]]\n",
    "                output_data = self.compiled_df.loc[output_times, \"Lightning_Risk\"].astype(int).values.flatten()\n",
    "                if self.reject_zeros and not (output_data == 1).any():\n",
    "                    continue \n",
    "                self.samples.append((input_tensor, output_data))\n",
    "            except KeyError:\n",
    "                continue  # Skip if any timestamps are missing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        # x: shape (C, T, H, W) → permute to (T, C, H, W) for model\n",
    "        x = torch.tensor(x, dtype=torch.float32).permute(1, 0, 2, 3)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        return x, y\n",
    "    \n",
    "    def get_positive_ratio(self):\n",
    "        all_labels = np.array([sample[1] for sample in self.samples])  # shape (N, 5)\n",
    "        total = all_labels.size\n",
    "        positives = (all_labels == 1).sum()\n",
    "        return positives / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LightningDataset_Modified(data,pixel_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3469391",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a901063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_positive_ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e155b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator(device=\"cuda\") if torch.cuda.is_available() else torch.Generator()\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, generator=g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b209e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningRiskCNNRNN(nn.Module):\n",
    "    def __init__(self, num_channels=5, num_future_steps=5, hidden_size=256):\n",
    "        super(LightningRiskCNNRNN, self).__init__()\n",
    "\n",
    "        # --- CNN Feature Extractor ---\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=32, kernel_size=5, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Dynamically determine CNN output size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, num_channels, 9, 18)\n",
    "            x = F.relu(self.conv1(dummy_input))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.relu(self.conv3(x))\n",
    "            self.feature_size = self.flatten(x).shape[1]\n",
    "\n",
    "        # --- RNN ---\n",
    "        self.rnn = nn.RNN(input_size=self.feature_size, hidden_size=hidden_size, batch_first=True)\n",
    "\n",
    "        # --- Output Layer ---\n",
    "        self.fc = nn.Linear(hidden_size, num_future_steps)\n",
    "\n",
    "        # --- Learnable initial hidden state ---\n",
    "        self.initial_hidden_state = nn.Parameter(torch.randn(1, 1, hidden_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len=5, channels=5, height, width)\n",
    "        batch_size, seq_len, c, h, w = x.shape\n",
    "\n",
    "        cnn_features = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t]  # (batch, channels, height, width)\n",
    "            x_t = torch.nan_to_num(x_t, nan=0.0)\n",
    "\n",
    "            out = F.relu(self.conv1(x_t))\n",
    "            out = F.relu(self.conv2(out))\n",
    "            out = F.relu(self.conv3(out))\n",
    "            out = self.flatten(out)\n",
    "\n",
    "            cnn_features.append(out)\n",
    "\n",
    "        cnn_features = torch.stack(cnn_features, dim=1)  # (batch_size, seq_len, feature_size)\n",
    "\n",
    "        # Expand learnable hidden state for batch\n",
    "        h0 = self.initial_hidden_state.expand(1, batch_size, -1).contiguous()\n",
    "\n",
    "        # RNN\n",
    "        rnn_out, _ = self.rnn(cnn_features, h0)\n",
    "\n",
    "        # Final hidden state\n",
    "        final_hidden = rnn_out[:, -1, :]  # (batch_size, hidden_size)\n",
    "\n",
    "        # Risk prediction (sigmoid for binary/multi-label classification)\n",
    "        predictions = torch.sigmoid(self.fc(final_hidden))  # (batch_size, num_future_steps)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningRiskCNNRNN().to(device)\n",
    "# Get one batch\n",
    "for batch_x, batch_y in dataloader:\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ef0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, num_epochs, learning_rate, device=device):\n",
    "    model.train()\n",
    "    model.to(device)  # Ensure model is on GPU/CPU\n",
    "\n",
    "    # Binary Cross Entropy Loss for multi-label binary outputs\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # List to track the average loss for every epoch (including epoch 0)\n",
    "    avg_loss_history = []\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok=True)  # Ensure the directory exists\n",
    "    timestamp = datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)   # (B, T, C, H, W)\n",
    "            targets = targets.to(device)  # (B, 5) — each value ∈ [0, 1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predictions = model(inputs)  # Output shape: (B, 5)\n",
    "\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "        # Save the average loss every 5 epochs for monitoring\n",
    "        if (epoch) % 5 == 0:\n",
    "            avg_loss_history.append(avg_loss)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if (epoch) % 20 == 0:\n",
    "            filename = f'model_{timestamp}_{avg_loss:0.6f}_{epoch}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(\"models\", filename))\n",
    "            print(f\"Model saved as {filename}\")\n",
    "\n",
    "    # Save the model with timestamp and final loss at the end of training\n",
    "    final_loss = avg_loss_history[-1] if avg_loss_history else 0\n",
    "    \n",
    "    filename = f'model_{timestamp}_{final_loss:0.6f}.pth'\n",
    "\n",
    "    # Save model state\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(\"models\", filename))\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "    # Plotting the average loss every epoch (including epoch 0) in two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot with standard y-axis\n",
    "    axs[0].plot(range(0,num_epochs,5), avg_loss_history, label='Average Loss (every epoch)', color='blue')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].set_title('Average Training Loss Over Time (Standard Y-Axis)')\n",
    "    axs[0].grid(True)\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot with logarithmic y-axis\n",
    "    axs[1].plot(range(0,num_epochs,5), avg_loss_history, label='Average Loss (every epoch)', color='blue')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_title('Average Training Loss Over Time (Logarithmic Y-Axis)')\n",
    "    axs[1].set_yscale('log')  # Set the y-axis to logarithmic scale\n",
    "    axs[1].grid(True)\n",
    "    axs[1].legend()\n",
    "\n",
    "    # Save the plot as an image\n",
    "    os.makedirs(\"plots\", exist_ok=True)  # Ensure the directory exists\n",
    "    plot_filename = f'loss_plot_{timestamp}.png'\n",
    "    plt.savefig(os.path.join(\"plots\", plot_filename))\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    return avg_loss_history  # Return the loss history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningRiskCNNRNN().to(device)\n",
    "%timeit -r 1 -n 1 train(dataloader = dataloader, model = model, num_epochs = 500, learning_rate = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(dataloader, model, device=device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model.to(device)  # Ensure the model is on the correct device (GPU/CPU)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients during evaluation\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)  # (B, T, C, H, W)\n",
    "            targets = targets.to(device)  # (B, 5) — each value ∈ [0, 1]\n",
    "\n",
    "            predictions = model(inputs)  # Output shape: (B, 5)\n",
    "\n",
    "            # Convert predictions to binary (0 or 1) based on a threshold of 0.5\n",
    "            predicted_labels = (predictions > 0.5).float()\n",
    "\n",
    "            # Calculate number of correct predictions\n",
    "            correct_predictions += (predicted_labels == targets).sum().item()\n",
    "            total_predictions += targets.numel()  # Total number of elements in the target tensor\n",
    "\n",
    "    # Calculate accuracy as the percentage of correct predictions\n",
    "    accuracy = correct_predictions / total_predictions * 100  # Percentage accuracy\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = LightningDataset_Modified(data,pixel_coords,reject_zeros=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc86480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a test_dataloader prepared\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=True, generator=g)\n",
    "accuracy = evaluate_accuracy(validation_dataloader, model, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b109f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_epoch(filename):\n",
    "    match = re.search(r\"_(\\d+)\\.pth$\", filename)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "def evaluate_all_checkpoints(model_class, checkpoint_dir, train_loader, val_loader, device=\"cuda\"):\n",
    "    model_paths = sorted(glob.glob(f\"./models/{checkpoint_dir}_*.pth\"), key=extract_epoch)\n",
    "    results = []\n",
    "    best_val_acc = -1\n",
    "    best_model_state = None\n",
    "\n",
    "    for path in model_paths:\n",
    "        epoch = extract_epoch(path)\n",
    "        if epoch // 1 != epoch or epoch == -1:\n",
    "            continue\n",
    "        print(f\"\\nEvaluating model at epoch {epoch}...\")\n",
    "\n",
    "        # Initialize model and load state dict\n",
    "        model = model_class()\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "        train_acc = evaluate_accuracy(train_loader, model, device)\n",
    "        val_acc = evaluate_accuracy(val_loader, model, device)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Acc = {train_acc:.2f}% | Val Acc = {val_acc:.2f}%\")\n",
    "        results.append((epoch, train_acc, val_acc))\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # Save the best model\n",
    "    if best_model_state:\n",
    "        best_path = f\"./models/{checkpoint_dir}_best.pth\"\n",
    "        torch.save(best_model_state, best_path)\n",
    "        print(f\"\\n✅ Best model saved to {best_path} with Val Acc = {best_val_acc:.2f}%\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_validation(results, save_path):\n",
    "    # Unpack results\n",
    "    epochs = [r[0] for r in results]\n",
    "    train_accuracies = [r[1] for r in results]\n",
    "    val_accuracies = [r[2] for r in results]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_accuracies, label=\"Train Accuracy\", marker='o', linestyle='-')\n",
    "    plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\", marker='x', linestyle='--')\n",
    "    plt.title(\"Model Accuracy Over Epochs\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save to file\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    print(f\"Accuracy plot saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timestamp = \"model_2025_04_18_01_35\"\n",
    "\n",
    "results = evaluate_all_checkpoints(\n",
    "    model_class=LightningRiskCNNRNN,\n",
    "    checkpoint_dir=model_timestamp,  # Folder with .pth files\n",
    "    train_loader=dataloader,\n",
    "    val_loader=validation_dataloader,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "plot_accuracy_validation(results,f\"./plots/{model_timestamp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a2a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and base filename pattern\n",
    "file_path_test = \"../data/test_data/cleaned_compiled_data_normalized.csv\"\n",
    "\n",
    "# Load and concatenate all parts\n",
    "test_data = pd.read_csv(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eddb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LightningDataset_Modified(test_data,pixel_coords,reject_zeros=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e771382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot_checkpoints(model_class, checkpoint_dir, train_loader, val_loader, test_loader, device=\"cuda\"):\n",
    "    def extract_epoch(filename):\n",
    "        match = re.search(r\"_(\\d+)\\.pth$\", filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "\n",
    "    model_paths = sorted(glob.glob(f\"./models/{checkpoint_dir}_*.pth\"), key=extract_epoch)\n",
    "    results = []\n",
    "    best_val_acc = -1\n",
    "    best_model_state = None\n",
    "    best_test_acc = -1\n",
    "\n",
    "    for path in model_paths:\n",
    "        epoch = extract_epoch(path)\n",
    "        if epoch // 1 != epoch or epoch == -1:\n",
    "            continue\n",
    "        print(f\"\\n🔍 Evaluating model at epoch {epoch}...\")\n",
    "\n",
    "        # Initialize model and load weights\n",
    "        model = model_class()\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "\n",
    "        # Evaluate on all splits\n",
    "        train_acc = evaluate_accuracy(train_loader, model, device)\n",
    "        val_acc = evaluate_accuracy(val_loader, model, device)\n",
    "        test_acc = evaluate_accuracy(test_loader, model, device)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Acc = {train_acc:.2f}% | Val Acc = {val_acc:.2f}% | Test Acc = {test_acc:.2f}%\")\n",
    "        results.append((epoch, train_acc, val_acc, test_acc))\n",
    "\n",
    "        # Track best validation model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # Save best model weights\n",
    "    if best_model_state:\n",
    "        best_model_path = f\"./models/{checkpoint_dir}_best.pth\"\n",
    "        torch.save(best_model_state, best_model_path)\n",
    "        print(f\"\\n✅ Best model saved to {best_model_path} with Val Acc = {best_val_acc:.2f}%\")\n",
    "\n",
    "        # Save best test accuracy\n",
    "        test_acc_path = f\"./models/{checkpoint_dir}_best_test.txt\"\n",
    "        with open(test_acc_path, \"w\") as f:\n",
    "            f.write(f\"Best Validation Accuracy: {best_val_acc:.2f}%\\n\")\n",
    "            f.write(f\"Test Accuracy at Best Val: {best_test_acc:.2f}%\\n\")\n",
    "        print(f\"✅ Test accuracy saved to {test_acc_path}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    if results:\n",
    "        epochs = [r[0] for r in results]\n",
    "        train_accuracies = [r[1] for r in results]\n",
    "        val_accuracies = [r[2] for r in results]\n",
    "        test_accuracies = [r[3] for r in results]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(epochs, train_accuracies, label=\"Train Accuracy\", marker='o', linestyle='-')\n",
    "        plt.plot(epochs, val_accuracies, label=\"Validation Accuracy\", marker='x', linestyle='--')\n",
    "        plt.plot(epochs, test_accuracies, label=\"Test Accuracy\", marker='s', linestyle=':')\n",
    "        plt.title(\"Model Accuracy Over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy (%)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plot_path = f\"./models/{checkpoint_dir}_accuracy_plot.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.show()\n",
    "        print(f\"📊 Accuracy plot saved to {plot_path}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_timestamp = \"model_2025_04_18_01_35\"\n",
    "\n",
    "results = evaluate_and_plot_checkpoints(\n",
    "    model_class=LightningRiskCNNRNN,\n",
    "    checkpoint_dir=model_timestamp,  # Folder with .pth files\n",
    "    train_loader=dataloader,\n",
    "    val_loader=validation_dataloader,test_loader = test_dataloader,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566a497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

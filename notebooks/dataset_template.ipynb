{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64c545b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "scripts_dir = os.path.abspath(os.path.join(os.getcwd(), '..', 'scripts'))\n",
    "sys.path.append(scripts_dir)\n",
    "from data_generator import normalize_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c58c877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09507d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 files. Final shape: (221369, 42)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory and base filename pattern\n",
    "file_pattern = \"../data/final_data/cleaned_compiled_data_normalized_part*.csv\"\n",
    "\n",
    "# Use glob to get a sorted list of all matching CSV parts\n",
    "csv_files = sorted(glob.glob(file_pattern))\n",
    "\n",
    "# Load and concatenate all parts\n",
    "data = pd.concat((pd.read_csv(f) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# Done! Now `data` holds the full combined normalized DataFrame\n",
    "print(f\"Loaded {len(csv_files)} files. Final shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e86fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningDataset(Dataset):\n",
    "    def __init__(self, compiled_df, timezone_str=\"Asia/Singapore\"):\n",
    "        self.compiled_df = compiled_df.copy()\n",
    "        self.timezone = pytz.timezone(timezone_str)\n",
    "        self.samples = []\n",
    "\n",
    "        self._prepare_dataset()\n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        # Ensure datetime index\n",
    "        self.compiled_df[\"Timestamp\"] = pd.to_datetime(self.compiled_df[\"Timestamp\"])\n",
    "        if not isinstance(self.compiled_df.index, pd.DatetimeIndex):\n",
    "            self.compiled_df.set_index(\"Timestamp\", inplace=True)\n",
    "        self.compiled_df.index = self.compiled_df.index.tz_localize(None)\n",
    "\n",
    "        # Prepare input features and drop target\n",
    "        input_df = self.compiled_df.drop(columns=[\"Lightning_Risk\"])\n",
    "        input_columns = input_df.columns.values.tolist()\n",
    "\n",
    "        # Get valid timestamps\n",
    "        min_ts = self.compiled_df.index.min().ceil(\"2h\") + pd.Timedelta(hours=2)\n",
    "        max_ts = self.compiled_df.index.max().floor(\"2h\")\n",
    "        valid_ts = self.compiled_df.loc[\n",
    "            (self.compiled_df.index >= min_ts) &\n",
    "            (self.compiled_df.index <= max_ts) &\n",
    "            (self.compiled_df.index.hour % 2 == 0) &\n",
    "            (self.compiled_df.index.minute == 0)\n",
    "        ].index\n",
    "\n",
    "        for timestamp in valid_ts:\n",
    "            try:\n",
    "                # Input time windows (past)\n",
    "                input_times = [timestamp - pd.Timedelta(minutes=delta) for delta in [120, 90, 60, 30, 0]]\n",
    "                input_data = input_df.loc[input_times].values.flatten()\n",
    "\n",
    "                # Output time windows (future)\n",
    "                output_times = [timestamp + pd.Timedelta(minutes=delta) for delta in [0, 30, 60, 90, 120]]\n",
    "                output_data = self.compiled_df.loc[output_times, \"Lightning_Risk\"].astype(int).values.flatten()\n",
    "\n",
    "                self.samples.append((input_data, output_data))\n",
    "            except KeyError:\n",
    "                continue  # Skip if any timestamps are missing\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef17448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LightningDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4069540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8398"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "facfb866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8630,\n",
       "         0.5796, 0.8315, 0.7320, 0.7548, 0.8262, 0.8262, 0.8208, 0.5448, 0.6825,\n",
       "         0.4646, 0.5755, 0.5682, 0.5555, 0.5392, 0.4169, 0.1023, 0.6465, 0.1563,\n",
       "         0.4115, 0.5093, 0.1984, 0.3096, 0.1798, 0.1312, 0.4850, 0.5158, 0.9292,\n",
       "         0.6648, 0.3130, 0.8303, 0.6496, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.8784, 0.5796, 0.8101, 0.7548, 0.7088, 0.8473,\n",
       "         0.8630, 0.7263, 0.5306, 0.6855, 0.5055, 0.5088, 0.5981, 0.5893, 0.5276,\n",
       "         0.5216, 0.0954, 0.6576, 0.2164, 0.3348, 0.5329, 0.2008, 0.2839, 0.3110,\n",
       "         0.0000, 0.4907, 0.5130, 0.5703, 0.6227, 0.4072, 0.8544, 0.5703, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8155, 0.5796,\n",
       "         0.8421, 0.7992, 0.7263, 0.8315, 0.8155, 0.7435, 0.5632, 0.6870, 0.5121,\n",
       "         0.4604, 0.6065, 0.5682, 0.5448, 0.5420, 0.1674, 0.6391, 0.1629, 0.2839,\n",
       "         0.4812, 0.2361, 0.3069, 0.2974, 0.3757, 0.4703, 0.4674, 0.5501, 0.6112,\n",
       "         0.4205, 0.8163, 0.5947, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.7883, 0.7088, 0.7828, 0.7883, 0.7605, 0.8262, 0.7828,\n",
       "         0.7772, 0.6763, 0.5529, 0.5502, 0.4055, 0.5682, 0.6206, 0.5731, 0.4561,\n",
       "         0.2103, 0.3843, 0.2311, 0.2826, 0.3978, 0.2349, 0.2773, 0.2474, 0.4072,\n",
       "         0.3296, 0.4429, 0.4238, 0.5899, 0.3087, 0.1037, 0.4674, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7828, 0.7320, 0.8155,\n",
       "         0.7205, 0.7030, 0.7717, 0.7661, 0.7030, 0.6569, 0.5502, 0.5555, 0.4843,\n",
       "         0.5657, 0.6127, 0.6107, 0.5731, 0.2525, 0.3348, 0.2249, 0.3680, 0.5312,\n",
       "         0.2564, 0.3083, 0.3505, 0.3214, 0.0702, 0.4270, 0.9477, 0.5728, 0.3416,\n",
       "         0.3214, 0.6112], device='cuda:0'),\n",
       " tensor([0., 0., 0., 0., 0.], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4c5fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

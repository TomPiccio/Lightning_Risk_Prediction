{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419f9829",
   "metadata": {},
   "source": [
    "# Best Models\n",
    "Chan Wei Jian Ivan\n",
    "1005924\n",
    "Tom Manuel Opalla Piccio\n",
    "1006293\n",
    "Deshpande Sunny Nitin\n",
    "1006336\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6084a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch.utils.data import ConcatDataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9fde2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and base filename pattern\n",
    "file_path_test = \"data/test_data/cleaned_compiled_data_normalized.csv\"\n",
    "\n",
    "# Load and concatenate all parts\n",
    "test_data = pd.read_csv(file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b660a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.set_default_device(device)\n",
    "\n",
    "g = torch.Generator(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "217dd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_sigmoid(x):\n",
    "    # If all outputs are already in [0, 1], assume sigmoid already applied\n",
    "    if x.min() >= 0 and x.max() <= 1:\n",
    "        return x  # Already probabilities\n",
    "    return torch.sigmoid(x)  # Assume logits\n",
    "\n",
    "def evaluate_metrics(dataloader, model, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            # Convert from NumPy if needed\n",
    "            if isinstance(inputs, np.ndarray):\n",
    "                inputs = torch.tensor(inputs)\n",
    "            if isinstance(targets, np.ndarray):\n",
    "                targets = torch.tensor(targets)\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            probs = safe_sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    accuracy = (all_preds == all_targets).mean() * 100\n",
    "    precision = precision_score(all_targets, all_preds, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(all_targets, all_preds, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    print(\"ðŸ”Ž Evaluation Results for LSTM Model\")\n",
    "    print(\"====================================\")\n",
    "    print(f\"âœ… Accuracy : {accuracy:.2f}%\")\n",
    "    print(f\"ðŸŽ¯ Precision: {precision:.4f}\")\n",
    "    print(f\"ðŸ” Recall   : {recall:.4f}\")\n",
    "    print(f\"ðŸ“Š F1 Score : {f1:.4f}\")\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a0f4de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Term 8\\Deep Learning\\Lightning_Risk_Prediction\\LSTM\\LSTM.py:48: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  self.compiled_df[col] = self.compiled_df[col].interpolate(limit_direction='both')\n"
     ]
    }
   ],
   "source": [
    "from LSTM import LSTM_Dataset,LSTM_Module\n",
    "LSTM_dataset = LSTM_Dataset(test_data)\n",
    "LSTM_dataloader = DataLoader(LSTM_dataset, batch_size=64, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f513d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomma\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_Module(\n",
       "  (lstm): LSTM(35, 128, batch_first=True, dropout=0.2)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model = LSTM_Module(\n",
    "    hours_lookback=6,  # adjust if different\n",
    "    input_dim=35,      # make sure it matches your input feature size\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.2\n",
    ")\n",
    "LSTM_model_path = r'LSTM/LSTM.pth'\n",
    "LSTM_model.load_state_dict(torch.load(LSTM_model_path, map_location=device))\n",
    "LSTM_model.to(device)\n",
    "LSTM_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec76915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Evaluation Results for LSTM Model\n",
      "====================================\n",
      "âœ… Accuracy : 93.21%\n",
      "ðŸŽ¯ Precision: 0.4831\n",
      "ðŸ” Recall   : 0.1989\n",
      "ðŸ“Š F1 Score : 0.2627\n"
     ]
    }
   ],
   "source": [
    "LSTM_results = evaluate_metrics(LSTM_dataloader,LSTM_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7495c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_stations = ['S104', 'S107', 'S109', 'S115', 'S116', 'S43', 'S50']\n",
    "pixel_coords = [(4, 11, 'S109'),\n",
    " (2, 7, 'S50'),\n",
    " (1, 16, 'S107'),\n",
    " (2, 13, 'S43'),\n",
    " (0, 0, 'S115'),\n",
    " (0, 6, 'S116'),\n",
    " (8, 8, 'S104')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37a90156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_RNN import CNN_RNN_Dataset, CNN_RNN_Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a55d92f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabular_to_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m CNN_RNN_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCNN_RNN_Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpixel_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m CNN_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(LSTM_Dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, generator\u001b[38;5;241m=\u001b[39mg)\n",
      "File \u001b[1;32md:\\Documents\\Term 8\\Deep Learning\\Lightning_Risk_Prediction\\CNN_RNN\\CNN_RNN.py:28\u001b[0m, in \u001b[0;36mCNN_RNN_Dataset.__init__\u001b[1;34m(self, compiled_df, pixel_coords, image_shape, timezone_str, reject_zeros)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreject_zeros \u001b[38;5;241m=\u001b[39m reject_zeros\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrejected_samples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Documents\\Term 8\\Deep Learning\\Lightning_Risk_Prediction\\CNN_RNN\\CNN_RNN.py:55\u001b[0m, in \u001b[0;36mCNN_RNN_Dataset._prepare_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m input_times \u001b[38;5;241m=\u001b[39m [timestamp \u001b[38;5;241m-\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(minutes\u001b[38;5;241m=\u001b[39mdelta) \u001b[38;5;28;01mfor\u001b[39;00m delta \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m     54\u001b[0m input_slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_df\u001b[38;5;241m.\u001b[39mloc[input_times]\n\u001b[1;32m---> 55\u001b[0m input_images \u001b[38;5;241m=\u001b[39m \u001b[43mtabular_to_image\u001b[49m(input_slices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpixel_coords, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_shape)  \u001b[38;5;66;03m# (5, H, W, C)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Rearrange to (C, T, H, W) if needed\u001b[39;00m\n\u001b[0;32m     58\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(input_images, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# (C, T, H, W)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tabular_to_image' is not defined"
     ]
    }
   ],
   "source": [
    "CNN_RNN_dataset = CNN_RNN_Dataset(test_data,pixel_coords)\n",
    "CNN_dataloader = DataLoader(LSTM_Dataset, batch_size=64, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82969c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
